"""
Kitap arama ve zenginleÅŸtirme servisi
"""
import logging
from typing import Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
import asyncio

from scrapers.kitapyurdu import KitapyurduScraper
from scrapers.goodreads import GoodreadsScraper
from scrapers.binkitap import BinKitapScraper
from utils.async_utils import run_sync
from utils.text_utils import metin_duzelt, benzerlik_orani
from utils.series_utils import translate_series_name, prefer_turkish_series

logger = logging.getLogger(__name__)


class BookService:
    """Kitap arama ve zenginleÅŸtirme servisi"""
    
    def __init__(self):
        self.scrapers = {
            'kitapyurdu': KitapyurduScraper(),
            'goodreads': GoodreadsScraper(),
            'binkitap': BinKitapScraper()
        }
        self.executor = ThreadPoolExecutor(max_workers=3)
    
    async def search_book(
        self, 
        query: str, 
        isbn: str = None,
        manuel_mod: bool = False
    ):
        """
        Kitap ara ve zenginleÅŸtir
        
        Returns:
            tuple: (kitap_bilgileri: dict|None, kaynak: str, basarili: bool)
        """
        logger.info(f"ğŸ” AranÄ±yor: {query}")
        
        try:
            # Kitapyurdu'da ara
            kitapyurdu_data = await self._search_kitapyurdu(query, isbn)
            
            if not kitapyurdu_data:
                logger.warning(f"âŒ HiÃ§bir kaynakta bulunamadÄ±: {query}")
                return (None, "Yok", False)  # â† TUPLE!
            
            # Kaynak bilgisi
            kaynak = "Kitapyurdu"
            kitapyurdu_data["kaynak"] = kaynak
            
            logger.info(f"âœ… Bulundu: {kaynak} - {kitapyurdu_data.get('baslik', 'N/A')}")
            
            # ZenginleÅŸtirme
            if not manuel_mod:
                enriched_data = await self._enrich_data(kitapyurdu_data)
                return (enriched_data, kaynak, True)  # â† TUPLE!
            else:
                logger.info("â„¹ï¸ Manuel mod, zenginleÅŸtirme atlandÄ±")
                return (kitapyurdu_data, kaynak, True)  # â† TUPLE!
        
        except Exception as e:
            logger.error(f"âŒ Arama hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return (None, "Hata", False)  # â† TUPLE!


    async def _search_kitapyurdu(self, query: str, isbn: str = None):
        """Kitapyurdu'da akÄ±llÄ± arama - 3 aÅŸamalÄ±"""
        import re
        
        scraper = self.scrapers.get('kitapyurdu')
        if not scraper:
            logger.error("âŒ Kitapyurdu scraper bulunamadÄ±")
            return None
        
        # ISBN varsa Ã¶nce ISBN ile ara
        if isbn:
            try:
                result = await run_sync(scraper.search, isbn)
                if result:
                    logger.info(f"âœ… ISBN ile bulundu: {isbn}")
                    return result
            except Exception as e:
                logger.debug(f"ISBN aramasÄ± baÅŸarÄ±sÄ±z: {e}")
        
        # 1ï¸âƒ£ TAM SORGU ile ara
        logger.info(f"ğŸ” [1/3] Tam sorgu: {query[:60]}...")
        try:
            result = await run_sync(scraper.search, query)
            if result:
                logger.info("âœ… Tam sorgu ile bulundu")
                return result
        except Exception as e:
            logger.debug(f"Tam sorgu hatasÄ±: {e}")
        
        # 2ï¸âƒ£ BASÄ°TLEÅTÄ°RÄ°LMÄ°Å SORGU (uzantÄ± ve boÅŸluklar temizlendi)
        basit = re.sub(r'\.(epub|pdf)$', '', query, flags=re.IGNORECASE)
        basit = basit.replace('_', ' ').replace('-', ' ')
        basit = re.sub(r'\s+', ' ', basit).strip()
        
        if basit != query:
            logger.info(f"ğŸ” [2/3] Basit sorgu: {basit[:60]}...")
            try:
                result = await run_sync(scraper.search, basit)
                if result:
                    logger.info("âœ… Basit sorgu ile bulundu")
                    return result
            except Exception as e:
                logger.debug(f"Basit sorgu hatasÄ±: {e}")
        
        # 3ï¸âƒ£ TEMÄ°Z SORGU (sayÄ±lar ve Ã¶zel karakterler temizlendi)
        temiz = re.sub(r'[^\wÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄÃœÅÄ°Ã–Ã‡\s]', ' ', basit)
        temiz = re.sub(r'\b\d+\b', '', temiz)  # SayÄ±larÄ± kaldÄ±r
        temiz = re.sub(r'\s+', ' ', temiz).strip()
        
        if temiz and temiz != basit:
            logger.info(f"ğŸ” [3/3] Temiz sorgu: {temiz[:60]}...")
            try:
                result = await run_sync(scraper.search, temiz)
                if result:
                    logger.info("âœ… Temiz sorgu ile bulundu")
                    return result
            except Exception as e:
                logger.debug(f"Temiz sorgu hatasÄ±: {e}")
        
        logger.warning(f"âŒ 3 aÅŸamada da bulunamadÄ±: {query[:60]}")
        return None    
    async def _enrich_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Kitap bilgilerini zenginleÅŸtir
        
        ZenginleÅŸtirme sÄ±rasÄ±:
        1. Goodreads (puan, tÃ¼r, orijinal ad, seri)
        2. 1000Kitap (Ã§evirmen, orijinal ad, seri)
        """
        logger.info("âœ¨ ZenginleÅŸtirme baÅŸlatÄ±lÄ±yor...")
        
        try:
            # Goodreads ile zenginleÅŸtir
            data = await self.enrich_with_goodreads(data, data.get("isbn"))
            
            # 1000Kitap ile zenginleÅŸtir
            data = await self.enrich_with_binkitap(data)
            
            logger.info("âœ… ZenginleÅŸtirme tamamlandÄ±")
        
        except Exception as e:
            logger.error(f"âŒ ZenginleÅŸtirme hatasÄ±: {e}")
            # Hata olsa bile ana veriyi koru!
        
        return data
    
    async def enrich_with_goodreads(
        self, 
        data: Dict[str, Any], 
        isbn: str = None
    ) -> Dict[str, Any]:
        """
        Goodreads ile zenginleÅŸtir
        - Orijinal ad â•
        - Puan
        - TÃ¼r
        - Seri â• (TÃ¼rkÃ§eleÅŸtirilmiÅŸ)
        - AÃ§Ä±klama
        """
        try:
            # ZenginleÅŸtirme gerekli mi kontrol et
            needs_enrichment = (
                not data.get("turu") or 
                not data.get("puan") or 
                not data.get("orijinal_ad") or
                not data.get("seri")
            )
            
            if not needs_enrichment:
                logger.info("â„¹ï¸ TÃ¼m bilgiler mevcut, Goodreads atlandÄ±")
                return data
            
            scraper = self.scrapers['goodreads']
            gr_result = None
            
            # 1ï¸âƒ£ Ä°lk olarak ISBN varsa ISBN ile ara
            if isbn or data.get("isbn"):
                search_term = isbn or data.get("isbn")
                logger.info(f"ğŸ” Goodreads'te aranÄ±yor: {search_term}...")
                
                try:
                    gr_result = await run_sync(
                        scraper.search, 
                        search_term, 
                        is_isbn_search=True
                    )
                except Exception as e:
                    error_str = str(e)
                    if "404" in error_str or "Not Found" in error_str:
                        logger.warning("âš ï¸ ISBN ile bulunamadÄ±, baÅŸlÄ±k+yazar ile deneniyor...")
                        gr_result = None
                    else:
                        logger.debug(f"Goodreads ISBN hatasÄ±: {e}")
                        gr_result = None
            
            # 2ï¸âƒ£ ISBN yoksa veya ISBN'de bulunamadÄ±ysa baÅŸlÄ±k+yazar ile ara
            if not gr_result:
                search_term = f"{data.get('baslik', '')} {data.get('yazar', '')}".strip()
                
                if not search_term:
                    return data
                
                logger.info(f"ğŸ” Goodreads'te aranÄ±yor: {search_term[:50]}...")
                
                try:
                    gr_result = await run_sync(scraper.search, search_term)
                except Exception as e:
                    logger.debug(f"Goodreads arama hatasÄ±: {e}")
                    return data
            
            if gr_result:
                updated = False
                
                # Orijinal ad
                if not data.get("orijinal_ad") and gr_result.get("orijinal_ad"):
                    data["orijinal_ad"] = gr_result["orijinal_ad"]
                    updated = True
                    logger.info(f"   â• Orijinal Ad: {data['orijinal_ad']}")
                
                # TÃ¼r
                if not data.get("turu") and gr_result.get("turu"):
                    data["turu"] = gr_result["turu"]
                    updated = True
                    logger.info(f"   â• TÃ¼r: {data['turu']}")
                
                # Puan
                if not data.get("puan") and gr_result.get("puan"):
                    data["puan"] = gr_result["puan"]
                    data["oy_sayisi"] = gr_result.get("oy_sayisi")
                    updated = True
                    logger.info(f"   â• Puan: {data['puan']} ({data.get('oy_sayisi')} oy)")
                
                # â• Seri (TÃ¼rkÃ§eleÅŸtirilmiÅŸ)
                if gr_result.get("seri"):
                    existing_series = data.get("seri")
                    translated_series = translate_series_name(gr_result["seri"])
                    final_series = prefer_turkish_series(existing_series, translated_series)
                    
                    if final_series and final_series != existing_series:
                        data["seri"] = final_series
                        updated = True
                        logger.info(f"   â• Seri: {data['seri']}")
                
                # AÃ§Ä±klama
                mevcut_aciklama = data.get("aciklama", "").lower()
                is_weak_desc = (
                    not data.get("aciklama") or 
                    len(data.get("aciklama", "")) < 25 or
                    "aÃ§Ä±klama bulunamadÄ±" in mevcut_aciklama
                )
                
                if is_weak_desc and gr_result.get("aciklama") and len(gr_result["aciklama"]) > 25:
                    data["aciklama"] = gr_result["aciklama"]
                    updated = True
                    logger.info("   â• AÃ§Ä±klama gÃ¼ncellendi")
                
                if updated:
                    logger.info("âœ… Goodreads ile zenginleÅŸtirildi")
                else:
                    logger.info("â„¹ï¸ Goodreads'ten yeni bilgi eklenmedi")
            else:
                logger.debug("âš ï¸ Goodreads'te sonuÃ§ bulunamadÄ±")
        
        except Exception as e:
            logger.error(f"âŒ Goodreads zenginleÅŸtirme hatasÄ±: {e}")
        
        return data
    
    async def enrich_with_binkitap(
        self, 
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        1000Kitap ile zenginleÅŸtir
        - Orijinal ad â•
        - Ã‡evirmen â•
        - Seri â• (Zaten TÃ¼rkÃ§e)
        """
        try:
            if data.get("orijinal_ad") and data.get("seri") and data.get("cevirmen"):
                logger.info("â„¹ï¸ TÃ¼m bilgiler mevcut, 1000Kitap atlandÄ±")
                return data
            
            if not data.get("baslik"):
                return data
            
            search_term = f"{data.get('baslik', '')} {data.get('yazar', '')}".strip()
            
            logger.info(f"ğŸ” 1000Kitap'ta aranÄ±yor: {search_term[:50]}...")
            
            scraper = self.scrapers['binkitap']
            
            try:
                bk_result = await run_sync(scraper.search, search_term)
            except Exception as e:
                logger.debug(f"1000Kitap arama hatasÄ±: {e}")
                return data
            
            if bk_result:
                benzerlik = benzerlik_orani(
                    data.get('baslik', ''), 
                    bk_result.get('baslik', '')
                )
                
                if benzerlik < 0.6:
                    logger.debug(f"âš ï¸ DÃ¼ÅŸÃ¼k benzerlik ({benzerlik:.2f}), atlanÄ±yor")
                    return data
                
                updated = False
                
                if not data.get("orijinal_ad") and bk_result.get("orijinal_ad"):
                    data["orijinal_ad"] = bk_result["orijinal_ad"]
                    updated = True
                    logger.info(f"   â• Orijinal Ad: {data['orijinal_ad']}")
                
                if not data.get("cevirmen") and bk_result.get("cevirmen"):
                    data["cevirmen"] = bk_result["cevirmen"]
                    updated = True
                    logger.info(f"   â• Ã‡evirmen: {data['cevirmen']}")
                
                if not data.get("seri") and bk_result.get("seri"):
                    data["seri"] = bk_result["seri"]
                    updated = True
                    logger.info(f"   â• Seri: {data['seri']}")
                
                if updated:
                    logger.info("âœ… 1000Kitap ile zenginleÅŸtirildi")
                else:
                    logger.info("â„¹ï¸ 1000Kitap'tan yeni bilgi eklenmedi")
            else:
                logger.debug("âš ï¸ 1000Kitap'ta sonuÃ§ bulunamadÄ±")
        
        except Exception as e:
            logger.error(f"âŒ 1000Kitap zenginleÅŸtirme hatasÄ±: {e}")
        
        return data
    
    def close(self):
        """KaynaklarÄ± temizle"""
        self.executor.shutdown(wait=False)




# ========================================
# ğŸ¯ Singleton Instance (Ã–NEMLÄ°!)
# ========================================
book_service = BookService()