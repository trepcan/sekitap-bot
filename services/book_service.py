"""
Kitap arama ve zenginleÅŸtirme servisi
"""
import logging
from typing import Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
import asyncio
import re

from scrapers.kitapyurdu import KitapyurduScraper
from scrapers.goodreads import GoodreadsScraper
from scrapers.binkitap import BinKitapScraper
from utils.async_utils import run_sync
from utils.text_utils import metin_duzelt, benzerlik_orani
from utils.series_utils import translate_series_name, prefer_turkish_series
from config.constants import GURULTU_KELIMELERI

logger = logging.getLogger(__name__)


class BookService:
    """Kitap arama ve zenginleÅŸtirme servisi"""
    
    def __init__(self):
        self.scrapers = {
            'kitapyurdu': KitapyurduScraper(),
            'goodreads': GoodreadsScraper(),
            'binkitap': BinKitapScraper()
        }
        self.executor = ThreadPoolExecutor(max_workers=3)
        
        # GÃ¼rÃ¼ltÃ¼ kelimelerini regex pattern'e Ã§evir (performans iÃ§in)
        self._gurultu_pattern = self._create_noise_pattern()
    
    def _create_noise_pattern(self) -> re.Pattern:
        """
        GÃ¼rÃ¼ltÃ¼ kelimelerinden tek bir regex pattern oluÅŸtur
        - Case insensitive
        - Kelime sÄ±nÄ±rlarÄ± ile eÅŸleÅŸme
        """
        # Ã–zel karakterleri escape et
        escaped_words = [re.escape(word) for word in GURULTU_KELIMELERI]
        
        # Regex pattern'i oluÅŸtur: \b(word1|word2|word3)\b
        pattern_str = r'\b(' + '|'.join(escaped_words) + r')\b'
        
        return re.compile(pattern_str, re.IGNORECASE | re.UNICODE)
    
    def _temizle_gurultu(self, text: str) -> str:
        """
        Metinden gÃ¼rÃ¼ltÃ¼ kelimelerini temizle
        
        Args:
            text: Temizlenecek metin
            
        Returns:
            str: TemizlenmiÅŸ metin
        """
        if not text:
            return text
        
        # 1. GÃ¼rÃ¼ltÃ¼ kelimelerini kaldÄ±r
        temiz = self._gurultu_pattern.sub(' ', text)
        
        # 2. YaygÄ±n ayÄ±rÄ±cÄ±larÄ± boÅŸluÄŸa Ã§evir
        temiz = re.sub(r'[_\-\.]+', ' ', temiz)
        
        # 3. KÃ¶ÅŸeli/normal parantez iÃ§indeki gÃ¼rÃ¼ltÃ¼yÃ¼ temizle
        # Ã–rnek: "[CS]", "(PDF)", "[Okundu]"
        temiz = re.sub(r'\[([^\]]*)\]', lambda m: '' if self._is_noise(m.group(1)) else m.group(0), temiz)
        temiz = re.sub(r'\(([^\)]*)\)', lambda m: '' if self._is_noise(m.group(1)) else m.group(0), temiz)
        
        # 4. Dosya uzantÄ±larÄ±nÄ± kaldÄ±r
        temiz = re.sub(r'\.(epub|pdf|mobi|azw3|djvu|txt)$', '', temiz, flags=re.IGNORECASE)
        
        # 5. SayÄ±+nokta formatÄ±nÄ± temizle (1. 2. 3.)
        temiz = re.sub(r'\b\d+\.\s*', ' ', temiz)
        
        # 6. Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa indir
        temiz = re.sub(r'\s+', ' ', temiz)
        
        return temiz.strip()
    
    def _is_noise(self, text: str) -> bool:
        """
        Verilen metnin tamamen gÃ¼rÃ¼ltÃ¼ olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        
        Args:
            text: Kontrol edilecek metin
            
        Returns:
            bool: GÃ¼rÃ¼ltÃ¼ ise True
        """
        if not text:
            return True
        
        text_lower = text.lower().strip()
        
        # BoÅŸ veya Ã§ok kÄ±sa
        if len(text_lower) < 2:
            return True
        
        # Sadece sayÄ± ve noktalama
        if re.match(r'^[\d\s\.\-_]+$', text_lower):
            return True
        
        # GÃ¼rÃ¼ltÃ¼ kelimesi kontrolÃ¼
        return text_lower in [g.lower() for g in GURULTU_KELIMELERI]
    
    async def search_book(
        self, 
        query: str, 
        isbn: str = None,
        manuel_mod: bool = False
    ):
        """
        Kitap ara ve zenginleÅŸtir
        
        Returns:
            tuple: (kitap_bilgileri: dict|None, kaynak: str, basarili: bool)
        """
        logger.info(f"ğŸ” AranÄ±yor (ham): {query}")
        
        # GÃ¼rÃ¼ltÃ¼ temizliÄŸi
        temiz_query = self._temizle_gurultu(query)
        logger.info(f"ğŸ§¹ TemizlenmiÅŸ sorgu: {temiz_query}")
        
        try:
            # Kitapyurdu'da ara
            kitapyurdu_data = await self._search_kitapyurdu(temiz_query, isbn)
            
            if not kitapyurdu_data:
                logger.warning(f"âŒ HiÃ§bir kaynakta bulunamadÄ±: {temiz_query}")
                return (None, "Yok", False)
            
            # Kaynak bilgisi
            kaynak = "Kitapyurdu"
            kitapyurdu_data["kaynak"] = kaynak
            
            logger.info(f"âœ… Bulundu: {kaynak} - {kitapyurdu_data.get('baslik', 'N/A')}")
            
            # ZenginleÅŸtirme
            if not manuel_mod:
                enriched_data = await self._enrich_data(kitapyurdu_data)
                return (enriched_data, kaynak, True)
            else:
                logger.info("â„¹ï¸ Manuel mod, zenginleÅŸtirme atlandÄ±")
                return (kitapyurdu_data, kaynak, True)
        
        except Exception as e:
            logger.error(f"âŒ Arama hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return (None, "Hata", False)

    async def _search_kitapyurdu(self, query: str, isbn: str = None):
        """Kitapyurdu'da akÄ±llÄ± arama - 6 aÅŸamalÄ± (gÃ¼rÃ¼ltÃ¼ temizlikli)"""
        
        scraper = self.scrapers.get('kitapyurdu')
        if not scraper:
            logger.error("âŒ Kitapyurdu scraper bulunamadÄ±")
            return None
        
        # ISBN varsa Ã¶nce ISBN ile ara
        if isbn:
            try:
                result = await run_sync(scraper.search, isbn)
                if result:
                    logger.info(f"âœ… ISBN ile bulundu: {isbn}")
                    return result
            except Exception as e:
                logger.debug(f"ISBN aramasÄ± baÅŸarÄ±sÄ±z: {e}")
        
        # Arama stratejileri listesi
        strategies = []
        
        # 0ï¸âƒ£ TEMÄ°Z SORGU (GÃ¼rÃ¼ltÃ¼ zaten temizlenmiÅŸ)
        if query and len(query) >= 3:
            strategies.append(("TemizlenmiÅŸ sorgu", query))
        
        # 1ï¸âƒ£ PARANTEZ Ä°Ã‡Ä° Ã–NCELÄ°KLÄ°
        # "Rehine (Vanish)" â†’ "Vanish"
        parantez_match = re.search(r'\(([^)]+)\)', query)
        if parantez_match:
            parantez_ici = parantez_match.group(1).strip()
            
            if len(parantez_ici) >= 3 and not self._is_noise(parantez_ici):
                # Yazar bilgisi varsa ekle
                yazar_match = re.match(r'^([^\s]+(?:\s+[^\s]+)?)', query)
                if yazar_match:
                    yazar = yazar_match.group(1)
                    strategies.append(("Parantez iÃ§i + Yazar", f"{parantez_ici} {yazar}"))
                
                strategies.append(("Parantez iÃ§i", parantez_ici))
        
        # 2ï¸âƒ£ PARANTEZ DIÅI (orijinal baÅŸlÄ±k)
        parantez_disindaki = re.sub(r'\([^)]*\)', '', query)
        parantez_disindaki = re.sub(r'\s+', ' ', parantez_disindaki).strip()
        
        if parantez_disindaki and len(parantez_disindaki) >= 3:
            strategies.append(("Parantez dÄ±ÅŸÄ±ndaki", parantez_disindaki))
        
        # 3ï¸âƒ£ SAYILARI KALDIR
        sayisiz = re.sub(r'\b\d+\b', '', query)
        sayisiz = re.sub(r'\s+', ' ', sayisiz).strip()
        
        if sayisiz != query and len(sayisiz) >= 3:
            strategies.append(("SayÄ±sÄ±z", sayisiz))
        
        # 4ï¸âƒ£ NOKTALAMA TEMÄ°ZLE
        noktalama_temiz = re.sub(r'[^\wÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄÃœÅÄ°Ã–Ã‡\s]', ' ', query)
        noktalama_temiz = re.sub(r'\s+', ' ', noktalama_temiz).strip()
        
        if noktalama_temiz != query and len(noktalama_temiz) >= 3:
            strategies.append(("Noktalama temiz", noktalama_temiz))
        
        # 5ï¸âƒ£ Ä°LK 2-3 KELÄ°ME (genelde yazar + kitap adÄ±)
        kelimeler = query.split()
        if len(kelimeler) >= 2:
            ilk_iki = ' '.join(kelimeler[:2])
            if len(ilk_iki) >= 5:
                strategies.append(("Ä°lk 2 kelime", ilk_iki))
            
            if len(kelimeler) >= 3:
                ilk_uc = ' '.join(kelimeler[:3])
                strategies.append(("Ä°lk 3 kelime", ilk_uc))
        
        # 6ï¸âƒ£ SON 2 KELÄ°ME (genelde kitap adÄ±)
        if len(kelimeler) >= 2:
            son_iki = ' '.join(kelimeler[-2:])
            if len(son_iki) >= 5:
                strategies.append(("Son 2 kelime", son_iki))
        
        # Her stratejiyi dene
        for index, (strateji_adi, sorgu) in enumerate(strategies, 1):
            if not sorgu or len(sorgu) < 3:
                continue
            
            logger.info(f"ğŸ” [{index}/{len(strategies)}] {strateji_adi}: '{sorgu[:60]}...'")
            
            try:
                result = await run_sync(scraper.search, sorgu)
                if result:
                    logger.info(f"âœ… {strateji_adi} ile bulundu!")
                    return result
            except Exception as e:
                logger.debug(f"{strateji_adi} hatasÄ±: {e}")
        
        logger.warning(f"âŒ {len(strategies)} aÅŸamada da bulunamadÄ±: {query[:60]}")
        return None

    async def _enrich_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Kitap bilgilerini zenginleÅŸtir
        
        ZenginleÅŸtirme sÄ±rasÄ±:
        1. Goodreads (puan, tÃ¼r, orijinal ad, seri)
        2. 1000Kitap (Ã§evirmen, orijinal ad, seri)
        """
        logger.info("âœ¨ ZenginleÅŸtirme baÅŸlatÄ±lÄ±yor...")
        
        try:
            # Goodreads ile zenginleÅŸtir
            data = await self.enrich_with_goodreads(data, data.get("isbn"))
            
            # 1000Kitap ile zenginleÅŸtir
            data = await self.enrich_with_binkitap(data)
            
            logger.info("âœ… ZenginleÅŸtirme tamamlandÄ±")
        
        except Exception as e:
            logger.error(f"âŒ ZenginleÅŸtirme hatasÄ±: {e}")
            # Hata olsa bile ana veriyi koru!
        
        return data
    
    async def enrich_with_goodreads(
        self, 
        data: Dict[str, Any], 
        isbn: str = None
    ) -> Dict[str, Any]:
        """
        Goodreads ile zenginleÅŸtir
        - Orijinal ad â•
        - Puan
        - TÃ¼r
        - Seri â• (TÃ¼rkÃ§eleÅŸtirilmiÅŸ)
        - AÃ§Ä±klama
        """
        try:
            # ZenginleÅŸtirme gerekli mi kontrol et
            needs_enrichment = (
                not data.get("turu") or 
                not data.get("puan") or 
                not data.get("orijinal_ad") or
                not data.get("seri")
            )
            
            if not needs_enrichment:
                logger.info("â„¹ï¸ TÃ¼m bilgiler mevcut, Goodreads atlandÄ±")
                return data
            
            scraper = self.scrapers['goodreads']
            gr_result = None
            
            # 1ï¸âƒ£ Ä°lk olarak ISBN varsa ISBN ile ara
            if isbn or data.get("isbn"):
                search_term = isbn or data.get("isbn")
                logger.info(f"ğŸ” Goodreads'te aranÄ±yor: {search_term}...")
                
                try:
                    gr_result = await run_sync(
                        scraper.search, 
                        search_term, 
                        is_isbn_search=True
                    )
                except Exception as e:
                    error_str = str(e)
                    if "404" in error_str or "Not Found" in error_str:
                        logger.warning("âš ï¸ ISBN ile bulunamadÄ±, baÅŸlÄ±k+yazar ile deneniyor...")
                        gr_result = None
                    else:
                        logger.debug(f"Goodreads ISBN hatasÄ±: {e}")
                        gr_result = None
            
            # 2ï¸âƒ£ ISBN yoksa veya ISBN'de bulunamadÄ±ysa baÅŸlÄ±k+yazar ile ara
            if not gr_result:
                search_term = f"{data.get('baslik', '')} {data.get('yazar', '')}".strip()
                
                if not search_term:
                    return data
                
                logger.info(f"ğŸ” Goodreads'te aranÄ±yor: {search_term[:50]}...")
                
                try:
                    gr_result = await run_sync(scraper.search, search_term)
                except Exception as e:
                    logger.debug(f"Goodreads arama hatasÄ±: {e}")
                    return data
            
            if gr_result:
                updated = False
                
                # Orijinal ad
                if not data.get("orijinal_ad") and gr_result.get("orijinal_ad"):
                    data["orijinal_ad"] = gr_result["orijinal_ad"]
                    updated = True
                    logger.info(f"   â• Orijinal Ad: {data['orijinal_ad']}")
                
                # TÃ¼r
                if not data.get("turu") and gr_result.get("turu"):
                    data["turu"] = gr_result["turu"]
                    updated = True
                    logger.info(f"   â• TÃ¼r: {data['turu']}")
                
                # Puan
                if not data.get("puan") and gr_result.get("puan"):
                    data["puan"] = gr_result["puan"]
                    data["oy_sayisi"] = gr_result.get("oy_sayisi")
                    updated = True
                    logger.info(f"   â• Puan: {data['puan']} ({data.get('oy_sayisi')} oy)")
                
                # â• Seri (TÃ¼rkÃ§eleÅŸtirilmiÅŸ)
                if gr_result.get("seri"):
                    existing_series = data.get("seri")
                    translated_series = translate_series_name(gr_result["seri"])
                    final_series = prefer_turkish_series(existing_series, translated_series)
                    
                    if final_series and final_series != existing_series:
                        data["seri"] = final_series
                        updated = True
                        logger.info(f"   â• Seri: {data['seri']}")
                
                # AÃ§Ä±klama
                mevcut_aciklama = data.get("aciklama", "").lower()
                is_weak_desc = (
                    not data.get("aciklama") or 
                    len(data.get("aciklama", "")) < 25 or
                    "aÃ§Ä±klama bulunamadÄ±" in mevcut_aciklama
                )
                
                if is_weak_desc and gr_result.get("aciklama") and len(gr_result["aciklama"]) > 25:
                    data["aciklama"] = gr_result["aciklama"]
                    updated = True
                    logger.info("   â• AÃ§Ä±klama gÃ¼ncellendi")
                
                if updated:
                    logger.info("âœ… Goodreads ile zenginleÅŸtirildi")
                else:
                    logger.info("â„¹ï¸ Goodreads'ten yeni bilgi eklenmedi")
            else:
                logger.debug("âš ï¸ Goodreads'te sonuÃ§ bulunamadÄ±")
        
        except Exception as e:
            logger.error(f"âŒ Goodreads zenginleÅŸtirme hatasÄ±: {e}")
        
        return data
    
    async def enrich_with_binkitap(
        self, 
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        1000Kitap ile zenginleÅŸtir
        - Orijinal ad â•
        - Ã‡evirmen â•
        - Seri â• (Zaten TÃ¼rkÃ§e)
        """
        try:
            if data.get("orijinal_ad") and data.get("seri") and data.get("cevirmen"):
                logger.info("â„¹ï¸ TÃ¼m bilgiler mevcut, 1000Kitap atlandÄ±")
                return data
            
            if not data.get("baslik"):
                return data
            
            search_term = f"{data.get('baslik', '')} {data.get('yazar', '')}".strip()
            
            logger.info(f"ğŸ” 1000Kitap'ta aranÄ±yor: {search_term[:50]}...")
            
            scraper = self.scrapers['binkitap']
            
            try:
                bk_result = await run_sync(scraper.search, search_term)
            except Exception as e:
                logger.debug(f"1000Kitap arama hatasÄ±: {e}")
                return data
            
            if bk_result:
                benzerlik = benzerlik_orani(
                    data.get('baslik', ''), 
                    bk_result.get('baslik', '')
                )
                
                if benzerlik < 0.6:
                    logger.debug(f"âš ï¸ DÃ¼ÅŸÃ¼k benzerlik ({benzerlik:.2f}), atlanÄ±yor")
                    return data
                
                updated = False
                
                if not data.get("orijinal_ad") and bk_result.get("orijinal_ad"):
                    data["orijinal_ad"] = bk_result["orijinal_ad"]
                    updated = True
                    logger.info(f"   â• Orijinal Ad: {data['orijinal_ad']}")
                
                if not data.get("cevirmen") and bk_result.get("cevirmen"):
                    data["cevirmen"] = bk_result["cevirmen"]
                    updated = True
                    logger.info(f"   â• Ã‡evirmen: {data['cevirmen']}")
                
                if not data.get("seri") and bk_result.get("seri"):
                    data["seri"] = bk_result["seri"]
                    updated = True
                    logger.info(f"   â• Seri: {data['seri']}")
                
                if updated:
                    logger.info("âœ… 1000Kitap ile zenginleÅŸtirildi")
                else:
                    logger.info("â„¹ï¸ 1000Kitap'tan yeni bilgi eklenmedi")
            else:
                logger.debug("âš ï¸ 1000Kitap'ta sonuÃ§ bulunamadÄ±")
        
        except Exception as e:
            logger.error(f"âŒ 1000Kitap zenginleÅŸtirme hatasÄ±: {e}")
        
        return data
    
    def close(self):
        """KaynaklarÄ± temizle"""
        self.executor.shutdown(wait=False)


# ========================================
# ğŸ¯ Singleton Instance (Ã–NEMLÄ°!)
# ========================================
book_service = BookService()